{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 - Data Preprocessing\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('churn_train.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, [0,1,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]].values\n",
    "y = dataset.iloc[:, 19].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3333 entries, KS to TN\n",
      "Data columns (total 20 columns):\n",
      "st              3333 non-null int64\n",
      " acclen         3333 non-null int64\n",
      " arcode         3333 non-null object\n",
      " phnum          3333 non-null object\n",
      " intplan        3333 non-null object\n",
      " voice          3333 non-null int64\n",
      "nummailmes      3333 non-null float64\n",
      " tdmin          3333 non-null int64\n",
      " tdcal          3333 non-null float64\n",
      " tdchar         3333 non-null float64\n",
      " temin          3333 non-null int64\n",
      " tecal          3333 non-null float64\n",
      " tecahr         3333 non-null float64\n",
      " tnmin          3333 non-null int64\n",
      " tn cal         3333 non-null float64\n",
      " tnchar         3333 non-null float64\n",
      " timin          3333 non-null int64\n",
      " tical          3333 non-null float64\n",
      " tichar ncsc    3333 non-null int64\n",
      " label          3333 non-null object\n",
      "dtypes: float64(8), int64(8), object(4)\n",
      "memory usage: 546.8+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>st</th>\n",
       "      <th>acclen</th>\n",
       "      <th>arcode</th>\n",
       "      <th>phnum</th>\n",
       "      <th>intplan</th>\n",
       "      <th>voice</th>\n",
       "      <th>nummailmes</th>\n",
       "      <th>tdmin</th>\n",
       "      <th>tdcal</th>\n",
       "      <th>tdchar</th>\n",
       "      <th>temin</th>\n",
       "      <th>tecal</th>\n",
       "      <th>tecahr</th>\n",
       "      <th>tnmin</th>\n",
       "      <th>tn cal</th>\n",
       "      <th>tnchar</th>\n",
       "      <th>timin</th>\n",
       "      <th>tical</th>\n",
       "      <th>tichar ncsc</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KS</th>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>382-4657</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>197.4</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OH</th>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>371-7191</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>195.5</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NJ</th>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>358-1921</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>121.2</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OH</th>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>375-9999</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>61.9</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OK</th>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>330-6626</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>148.3</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>118</td>\n",
       "      <td>510</td>\n",
       "      <td>391-8027</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>223.4</td>\n",
       "      <td>98</td>\n",
       "      <td>37.98</td>\n",
       "      <td>220.6</td>\n",
       "      <td>101</td>\n",
       "      <td>18.75</td>\n",
       "      <td>203.9</td>\n",
       "      <td>118</td>\n",
       "      <td>9.18</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MA</th>\n",
       "      <td>121</td>\n",
       "      <td>510</td>\n",
       "      <td>355-9993</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>24</td>\n",
       "      <td>218.2</td>\n",
       "      <td>88</td>\n",
       "      <td>37.09</td>\n",
       "      <td>348.5</td>\n",
       "      <td>108</td>\n",
       "      <td>29.62</td>\n",
       "      <td>212.6</td>\n",
       "      <td>118</td>\n",
       "      <td>9.57</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2.03</td>\n",
       "      <td>3</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MO</th>\n",
       "      <td>147</td>\n",
       "      <td>415</td>\n",
       "      <td>329-9001</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>79</td>\n",
       "      <td>26.69</td>\n",
       "      <td>103.1</td>\n",
       "      <td>94</td>\n",
       "      <td>8.76</td>\n",
       "      <td>211.8</td>\n",
       "      <td>96</td>\n",
       "      <td>9.53</td>\n",
       "      <td>7.1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LA</th>\n",
       "      <td>117</td>\n",
       "      <td>408</td>\n",
       "      <td>335-4719</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>184.5</td>\n",
       "      <td>97</td>\n",
       "      <td>31.37</td>\n",
       "      <td>351.6</td>\n",
       "      <td>80</td>\n",
       "      <td>29.89</td>\n",
       "      <td>215.8</td>\n",
       "      <td>90</td>\n",
       "      <td>9.71</td>\n",
       "      <td>8.7</td>\n",
       "      <td>4</td>\n",
       "      <td>2.35</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WV</th>\n",
       "      <td>141</td>\n",
       "      <td>415</td>\n",
       "      <td>330-8173</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>37</td>\n",
       "      <td>258.6</td>\n",
       "      <td>84</td>\n",
       "      <td>43.96</td>\n",
       "      <td>222.0</td>\n",
       "      <td>111</td>\n",
       "      <td>18.87</td>\n",
       "      <td>326.4</td>\n",
       "      <td>97</td>\n",
       "      <td>14.69</td>\n",
       "      <td>11.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN</th>\n",
       "      <td>65</td>\n",
       "      <td>415</td>\n",
       "      <td>329-6603</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>129.1</td>\n",
       "      <td>137</td>\n",
       "      <td>21.95</td>\n",
       "      <td>228.5</td>\n",
       "      <td>83</td>\n",
       "      <td>19.42</td>\n",
       "      <td>208.8</td>\n",
       "      <td>111</td>\n",
       "      <td>9.40</td>\n",
       "      <td>12.7</td>\n",
       "      <td>6</td>\n",
       "      <td>3.43</td>\n",
       "      <td>4</td>\n",
       "      <td>True.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RI</th>\n",
       "      <td>74</td>\n",
       "      <td>415</td>\n",
       "      <td>344-9403</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>187.7</td>\n",
       "      <td>127</td>\n",
       "      <td>31.91</td>\n",
       "      <td>163.4</td>\n",
       "      <td>148</td>\n",
       "      <td>13.89</td>\n",
       "      <td>196.0</td>\n",
       "      <td>94</td>\n",
       "      <td>8.82</td>\n",
       "      <td>9.1</td>\n",
       "      <td>5</td>\n",
       "      <td>2.46</td>\n",
       "      <td>0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IA</th>\n",
       "      <td>168</td>\n",
       "      <td>408</td>\n",
       "      <td>363-1107</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>128.8</td>\n",
       "      <td>96</td>\n",
       "      <td>21.90</td>\n",
       "      <td>104.9</td>\n",
       "      <td>71</td>\n",
       "      <td>8.92</td>\n",
       "      <td>141.1</td>\n",
       "      <td>128</td>\n",
       "      <td>6.35</td>\n",
       "      <td>11.2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.02</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MT</th>\n",
       "      <td>95</td>\n",
       "      <td>510</td>\n",
       "      <td>394-8006</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>156.6</td>\n",
       "      <td>88</td>\n",
       "      <td>26.62</td>\n",
       "      <td>247.6</td>\n",
       "      <td>75</td>\n",
       "      <td>21.05</td>\n",
       "      <td>192.3</td>\n",
       "      <td>115</td>\n",
       "      <td>8.65</td>\n",
       "      <td>12.3</td>\n",
       "      <td>5</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IA</th>\n",
       "      <td>62</td>\n",
       "      <td>415</td>\n",
       "      <td>366-9238</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>120.7</td>\n",
       "      <td>70</td>\n",
       "      <td>20.52</td>\n",
       "      <td>307.2</td>\n",
       "      <td>76</td>\n",
       "      <td>26.11</td>\n",
       "      <td>203.0</td>\n",
       "      <td>99</td>\n",
       "      <td>9.14</td>\n",
       "      <td>13.1</td>\n",
       "      <td>6</td>\n",
       "      <td>3.54</td>\n",
       "      <td>4</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NY</th>\n",
       "      <td>161</td>\n",
       "      <td>415</td>\n",
       "      <td>351-7269</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>332.9</td>\n",
       "      <td>67</td>\n",
       "      <td>56.59</td>\n",
       "      <td>317.8</td>\n",
       "      <td>97</td>\n",
       "      <td>27.01</td>\n",
       "      <td>160.6</td>\n",
       "      <td>128</td>\n",
       "      <td>7.23</td>\n",
       "      <td>5.4</td>\n",
       "      <td>9</td>\n",
       "      <td>1.46</td>\n",
       "      <td>4</td>\n",
       "      <td>True.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>85</td>\n",
       "      <td>408</td>\n",
       "      <td>350-8884</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>27</td>\n",
       "      <td>196.4</td>\n",
       "      <td>139</td>\n",
       "      <td>33.39</td>\n",
       "      <td>280.9</td>\n",
       "      <td>90</td>\n",
       "      <td>23.88</td>\n",
       "      <td>89.3</td>\n",
       "      <td>75</td>\n",
       "      <td>4.02</td>\n",
       "      <td>13.8</td>\n",
       "      <td>4</td>\n",
       "      <td>3.73</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT</th>\n",
       "      <td>93</td>\n",
       "      <td>510</td>\n",
       "      <td>386-2923</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>190.7</td>\n",
       "      <td>114</td>\n",
       "      <td>32.42</td>\n",
       "      <td>218.2</td>\n",
       "      <td>111</td>\n",
       "      <td>18.55</td>\n",
       "      <td>129.6</td>\n",
       "      <td>121</td>\n",
       "      <td>5.83</td>\n",
       "      <td>8.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.19</td>\n",
       "      <td>3</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VA</th>\n",
       "      <td>76</td>\n",
       "      <td>510</td>\n",
       "      <td>356-2992</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>33</td>\n",
       "      <td>189.7</td>\n",
       "      <td>66</td>\n",
       "      <td>32.25</td>\n",
       "      <td>212.8</td>\n",
       "      <td>65</td>\n",
       "      <td>18.09</td>\n",
       "      <td>165.7</td>\n",
       "      <td>108</td>\n",
       "      <td>7.46</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX</th>\n",
       "      <td>73</td>\n",
       "      <td>415</td>\n",
       "      <td>373-2782</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>224.4</td>\n",
       "      <td>90</td>\n",
       "      <td>38.15</td>\n",
       "      <td>159.5</td>\n",
       "      <td>88</td>\n",
       "      <td>13.56</td>\n",
       "      <td>192.8</td>\n",
       "      <td>74</td>\n",
       "      <td>8.68</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.51</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FL</th>\n",
       "      <td>147</td>\n",
       "      <td>415</td>\n",
       "      <td>396-5800</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>155.1</td>\n",
       "      <td>117</td>\n",
       "      <td>26.37</td>\n",
       "      <td>239.7</td>\n",
       "      <td>93</td>\n",
       "      <td>20.37</td>\n",
       "      <td>208.8</td>\n",
       "      <td>133</td>\n",
       "      <td>9.40</td>\n",
       "      <td>10.6</td>\n",
       "      <td>4</td>\n",
       "      <td>2.86</td>\n",
       "      <td>0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO</th>\n",
       "      <td>77</td>\n",
       "      <td>408</td>\n",
       "      <td>393-7984</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>62.4</td>\n",
       "      <td>89</td>\n",
       "      <td>10.61</td>\n",
       "      <td>169.9</td>\n",
       "      <td>121</td>\n",
       "      <td>14.44</td>\n",
       "      <td>209.6</td>\n",
       "      <td>64</td>\n",
       "      <td>9.43</td>\n",
       "      <td>5.7</td>\n",
       "      <td>6</td>\n",
       "      <td>1.54</td>\n",
       "      <td>5</td>\n",
       "      <td>True.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>130</td>\n",
       "      <td>415</td>\n",
       "      <td>358-1958</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>112</td>\n",
       "      <td>31.11</td>\n",
       "      <td>72.9</td>\n",
       "      <td>99</td>\n",
       "      <td>6.20</td>\n",
       "      <td>181.8</td>\n",
       "      <td>78</td>\n",
       "      <td>8.18</td>\n",
       "      <td>9.5</td>\n",
       "      <td>19</td>\n",
       "      <td>2.57</td>\n",
       "      <td>0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SC</th>\n",
       "      <td>111</td>\n",
       "      <td>415</td>\n",
       "      <td>350-2565</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>110.4</td>\n",
       "      <td>103</td>\n",
       "      <td>18.77</td>\n",
       "      <td>137.3</td>\n",
       "      <td>102</td>\n",
       "      <td>11.67</td>\n",
       "      <td>189.6</td>\n",
       "      <td>105</td>\n",
       "      <td>8.53</td>\n",
       "      <td>7.7</td>\n",
       "      <td>6</td>\n",
       "      <td>2.08</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VA</th>\n",
       "      <td>132</td>\n",
       "      <td>510</td>\n",
       "      <td>343-4696</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>81.1</td>\n",
       "      <td>86</td>\n",
       "      <td>13.79</td>\n",
       "      <td>245.2</td>\n",
       "      <td>72</td>\n",
       "      <td>20.84</td>\n",
       "      <td>237.0</td>\n",
       "      <td>115</td>\n",
       "      <td>10.67</td>\n",
       "      <td>10.3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NE</th>\n",
       "      <td>174</td>\n",
       "      <td>415</td>\n",
       "      <td>331-3698</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>124.3</td>\n",
       "      <td>76</td>\n",
       "      <td>21.13</td>\n",
       "      <td>277.1</td>\n",
       "      <td>112</td>\n",
       "      <td>23.55</td>\n",
       "      <td>250.7</td>\n",
       "      <td>115</td>\n",
       "      <td>11.28</td>\n",
       "      <td>15.5</td>\n",
       "      <td>5</td>\n",
       "      <td>4.19</td>\n",
       "      <td>3</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WY</th>\n",
       "      <td>57</td>\n",
       "      <td>408</td>\n",
       "      <td>357-3817</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>39</td>\n",
       "      <td>213.0</td>\n",
       "      <td>115</td>\n",
       "      <td>36.21</td>\n",
       "      <td>191.1</td>\n",
       "      <td>112</td>\n",
       "      <td>16.24</td>\n",
       "      <td>182.7</td>\n",
       "      <td>115</td>\n",
       "      <td>8.22</td>\n",
       "      <td>9.5</td>\n",
       "      <td>3</td>\n",
       "      <td>2.57</td>\n",
       "      <td>0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MT</th>\n",
       "      <td>54</td>\n",
       "      <td>408</td>\n",
       "      <td>418-6412</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>134.3</td>\n",
       "      <td>73</td>\n",
       "      <td>22.83</td>\n",
       "      <td>155.5</td>\n",
       "      <td>100</td>\n",
       "      <td>13.22</td>\n",
       "      <td>102.1</td>\n",
       "      <td>68</td>\n",
       "      <td>4.59</td>\n",
       "      <td>14.7</td>\n",
       "      <td>4</td>\n",
       "      <td>3.97</td>\n",
       "      <td>3</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MO</th>\n",
       "      <td>20</td>\n",
       "      <td>415</td>\n",
       "      <td>353-2630</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>109</td>\n",
       "      <td>32.30</td>\n",
       "      <td>258.2</td>\n",
       "      <td>84</td>\n",
       "      <td>21.95</td>\n",
       "      <td>181.5</td>\n",
       "      <td>102</td>\n",
       "      <td>8.17</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HI</th>\n",
       "      <td>49</td>\n",
       "      <td>510</td>\n",
       "      <td>410-7789</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>119.3</td>\n",
       "      <td>117</td>\n",
       "      <td>20.28</td>\n",
       "      <td>215.1</td>\n",
       "      <td>109</td>\n",
       "      <td>18.28</td>\n",
       "      <td>178.7</td>\n",
       "      <td>90</td>\n",
       "      <td>8.04</td>\n",
       "      <td>11.1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WI</th>\n",
       "      <td>114</td>\n",
       "      <td>415</td>\n",
       "      <td>373-7308</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>26</td>\n",
       "      <td>137.1</td>\n",
       "      <td>88</td>\n",
       "      <td>23.31</td>\n",
       "      <td>155.7</td>\n",
       "      <td>125</td>\n",
       "      <td>13.23</td>\n",
       "      <td>247.6</td>\n",
       "      <td>94</td>\n",
       "      <td>11.14</td>\n",
       "      <td>11.5</td>\n",
       "      <td>7</td>\n",
       "      <td>3.11</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IL</th>\n",
       "      <td>71</td>\n",
       "      <td>510</td>\n",
       "      <td>330-7137</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>186.1</td>\n",
       "      <td>114</td>\n",
       "      <td>31.64</td>\n",
       "      <td>198.6</td>\n",
       "      <td>140</td>\n",
       "      <td>16.88</td>\n",
       "      <td>206.5</td>\n",
       "      <td>80</td>\n",
       "      <td>9.29</td>\n",
       "      <td>13.8</td>\n",
       "      <td>5</td>\n",
       "      <td>3.73</td>\n",
       "      <td>4</td>\n",
       "      <td>True.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN</th>\n",
       "      <td>58</td>\n",
       "      <td>415</td>\n",
       "      <td>406-8445</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>22</td>\n",
       "      <td>224.1</td>\n",
       "      <td>127</td>\n",
       "      <td>38.10</td>\n",
       "      <td>238.8</td>\n",
       "      <td>85</td>\n",
       "      <td>20.30</td>\n",
       "      <td>174.2</td>\n",
       "      <td>86</td>\n",
       "      <td>7.84</td>\n",
       "      <td>11.5</td>\n",
       "      <td>7</td>\n",
       "      <td>3.11</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>106</td>\n",
       "      <td>408</td>\n",
       "      <td>404-5283</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>29</td>\n",
       "      <td>83.6</td>\n",
       "      <td>131</td>\n",
       "      <td>14.21</td>\n",
       "      <td>203.9</td>\n",
       "      <td>131</td>\n",
       "      <td>17.33</td>\n",
       "      <td>229.5</td>\n",
       "      <td>73</td>\n",
       "      <td>10.33</td>\n",
       "      <td>8.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.19</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OK</th>\n",
       "      <td>172</td>\n",
       "      <td>408</td>\n",
       "      <td>398-3632</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>203.9</td>\n",
       "      <td>109</td>\n",
       "      <td>34.66</td>\n",
       "      <td>234.0</td>\n",
       "      <td>123</td>\n",
       "      <td>19.89</td>\n",
       "      <td>160.7</td>\n",
       "      <td>65</td>\n",
       "      <td>7.23</td>\n",
       "      <td>17.8</td>\n",
       "      <td>4</td>\n",
       "      <td>4.81</td>\n",
       "      <td>4</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IA</th>\n",
       "      <td>45</td>\n",
       "      <td>415</td>\n",
       "      <td>399-5763</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>211.3</td>\n",
       "      <td>87</td>\n",
       "      <td>35.92</td>\n",
       "      <td>165.7</td>\n",
       "      <td>97</td>\n",
       "      <td>14.08</td>\n",
       "      <td>265.9</td>\n",
       "      <td>72</td>\n",
       "      <td>11.97</td>\n",
       "      <td>13.3</td>\n",
       "      <td>6</td>\n",
       "      <td>3.59</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT</th>\n",
       "      <td>100</td>\n",
       "      <td>408</td>\n",
       "      <td>340-9449</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>219.4</td>\n",
       "      <td>112</td>\n",
       "      <td>37.30</td>\n",
       "      <td>225.7</td>\n",
       "      <td>102</td>\n",
       "      <td>19.18</td>\n",
       "      <td>255.3</td>\n",
       "      <td>95</td>\n",
       "      <td>11.49</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.24</td>\n",
       "      <td>4</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NY</th>\n",
       "      <td>94</td>\n",
       "      <td>415</td>\n",
       "      <td>363-1123</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>190.4</td>\n",
       "      <td>91</td>\n",
       "      <td>32.37</td>\n",
       "      <td>92.0</td>\n",
       "      <td>107</td>\n",
       "      <td>7.82</td>\n",
       "      <td>224.8</td>\n",
       "      <td>108</td>\n",
       "      <td>10.12</td>\n",
       "      <td>13.6</td>\n",
       "      <td>17</td>\n",
       "      <td>3.67</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LA</th>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>361-2170</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>147.7</td>\n",
       "      <td>94</td>\n",
       "      <td>25.11</td>\n",
       "      <td>283.3</td>\n",
       "      <td>83</td>\n",
       "      <td>24.08</td>\n",
       "      <td>188.3</td>\n",
       "      <td>124</td>\n",
       "      <td>8.47</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SC</th>\n",
       "      <td>181</td>\n",
       "      <td>408</td>\n",
       "      <td>406-6304</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>229.9</td>\n",
       "      <td>130</td>\n",
       "      <td>39.08</td>\n",
       "      <td>144.4</td>\n",
       "      <td>93</td>\n",
       "      <td>12.27</td>\n",
       "      <td>262.4</td>\n",
       "      <td>110</td>\n",
       "      <td>11.81</td>\n",
       "      <td>14.2</td>\n",
       "      <td>4</td>\n",
       "      <td>3.83</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>127</td>\n",
       "      <td>408</td>\n",
       "      <td>392-5090</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>102.8</td>\n",
       "      <td>128</td>\n",
       "      <td>17.48</td>\n",
       "      <td>143.7</td>\n",
       "      <td>95</td>\n",
       "      <td>12.21</td>\n",
       "      <td>191.4</td>\n",
       "      <td>97</td>\n",
       "      <td>8.61</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MO</th>\n",
       "      <td>89</td>\n",
       "      <td>415</td>\n",
       "      <td>373-7713</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>178.7</td>\n",
       "      <td>81</td>\n",
       "      <td>30.38</td>\n",
       "      <td>233.7</td>\n",
       "      <td>74</td>\n",
       "      <td>19.86</td>\n",
       "      <td>131.9</td>\n",
       "      <td>120</td>\n",
       "      <td>5.94</td>\n",
       "      <td>9.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2.46</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ME</th>\n",
       "      <td>149</td>\n",
       "      <td>415</td>\n",
       "      <td>392-1376</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>18</td>\n",
       "      <td>148.5</td>\n",
       "      <td>106</td>\n",
       "      <td>25.25</td>\n",
       "      <td>114.5</td>\n",
       "      <td>106</td>\n",
       "      <td>9.73</td>\n",
       "      <td>178.3</td>\n",
       "      <td>98</td>\n",
       "      <td>8.02</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MS</th>\n",
       "      <td>103</td>\n",
       "      <td>510</td>\n",
       "      <td>390-6388</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>29</td>\n",
       "      <td>164.1</td>\n",
       "      <td>111</td>\n",
       "      <td>27.90</td>\n",
       "      <td>219.1</td>\n",
       "      <td>96</td>\n",
       "      <td>18.62</td>\n",
       "      <td>220.3</td>\n",
       "      <td>108</td>\n",
       "      <td>9.91</td>\n",
       "      <td>12.3</td>\n",
       "      <td>9</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>163</td>\n",
       "      <td>415</td>\n",
       "      <td>379-7290</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>197.2</td>\n",
       "      <td>90</td>\n",
       "      <td>33.52</td>\n",
       "      <td>188.5</td>\n",
       "      <td>113</td>\n",
       "      <td>16.02</td>\n",
       "      <td>211.1</td>\n",
       "      <td>94</td>\n",
       "      <td>9.50</td>\n",
       "      <td>7.8</td>\n",
       "      <td>8</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OK</th>\n",
       "      <td>52</td>\n",
       "      <td>415</td>\n",
       "      <td>397-9928</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>124.9</td>\n",
       "      <td>131</td>\n",
       "      <td>21.23</td>\n",
       "      <td>300.5</td>\n",
       "      <td>118</td>\n",
       "      <td>25.54</td>\n",
       "      <td>192.5</td>\n",
       "      <td>106</td>\n",
       "      <td>8.66</td>\n",
       "      <td>11.6</td>\n",
       "      <td>4</td>\n",
       "      <td>3.13</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WY</th>\n",
       "      <td>89</td>\n",
       "      <td>415</td>\n",
       "      <td>378-6924</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>115.4</td>\n",
       "      <td>99</td>\n",
       "      <td>19.62</td>\n",
       "      <td>209.9</td>\n",
       "      <td>115</td>\n",
       "      <td>17.84</td>\n",
       "      <td>280.9</td>\n",
       "      <td>112</td>\n",
       "      <td>12.64</td>\n",
       "      <td>15.9</td>\n",
       "      <td>6</td>\n",
       "      <td>4.29</td>\n",
       "      <td>3</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GA</th>\n",
       "      <td>122</td>\n",
       "      <td>510</td>\n",
       "      <td>411-5677</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>101</td>\n",
       "      <td>23.80</td>\n",
       "      <td>196.4</td>\n",
       "      <td>77</td>\n",
       "      <td>16.69</td>\n",
       "      <td>120.1</td>\n",
       "      <td>133</td>\n",
       "      <td>5.40</td>\n",
       "      <td>9.7</td>\n",
       "      <td>4</td>\n",
       "      <td>2.62</td>\n",
       "      <td>4</td>\n",
       "      <td>True.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT</th>\n",
       "      <td>60</td>\n",
       "      <td>415</td>\n",
       "      <td>400-2738</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>193.9</td>\n",
       "      <td>118</td>\n",
       "      <td>32.96</td>\n",
       "      <td>85.0</td>\n",
       "      <td>110</td>\n",
       "      <td>7.23</td>\n",
       "      <td>210.1</td>\n",
       "      <td>134</td>\n",
       "      <td>9.45</td>\n",
       "      <td>13.2</td>\n",
       "      <td>8</td>\n",
       "      <td>3.56</td>\n",
       "      <td>3</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MD</th>\n",
       "      <td>62</td>\n",
       "      <td>408</td>\n",
       "      <td>409-1856</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>321.1</td>\n",
       "      <td>105</td>\n",
       "      <td>54.59</td>\n",
       "      <td>265.5</td>\n",
       "      <td>122</td>\n",
       "      <td>22.57</td>\n",
       "      <td>180.5</td>\n",
       "      <td>72</td>\n",
       "      <td>8.12</td>\n",
       "      <td>11.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.11</td>\n",
       "      <td>4</td>\n",
       "      <td>True.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN</th>\n",
       "      <td>117</td>\n",
       "      <td>415</td>\n",
       "      <td>362-5899</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>118.4</td>\n",
       "      <td>126</td>\n",
       "      <td>20.13</td>\n",
       "      <td>249.3</td>\n",
       "      <td>97</td>\n",
       "      <td>21.19</td>\n",
       "      <td>227.0</td>\n",
       "      <td>56</td>\n",
       "      <td>10.22</td>\n",
       "      <td>13.6</td>\n",
       "      <td>3</td>\n",
       "      <td>3.67</td>\n",
       "      <td>5</td>\n",
       "      <td>True.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WV</th>\n",
       "      <td>159</td>\n",
       "      <td>415</td>\n",
       "      <td>377-1164</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>169.8</td>\n",
       "      <td>114</td>\n",
       "      <td>28.87</td>\n",
       "      <td>197.7</td>\n",
       "      <td>105</td>\n",
       "      <td>16.80</td>\n",
       "      <td>193.7</td>\n",
       "      <td>82</td>\n",
       "      <td>8.72</td>\n",
       "      <td>11.6</td>\n",
       "      <td>4</td>\n",
       "      <td>3.13</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OH</th>\n",
       "      <td>78</td>\n",
       "      <td>408</td>\n",
       "      <td>368-8555</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>193.4</td>\n",
       "      <td>99</td>\n",
       "      <td>32.88</td>\n",
       "      <td>116.9</td>\n",
       "      <td>88</td>\n",
       "      <td>9.94</td>\n",
       "      <td>243.3</td>\n",
       "      <td>109</td>\n",
       "      <td>10.95</td>\n",
       "      <td>9.3</td>\n",
       "      <td>4</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OH</th>\n",
       "      <td>96</td>\n",
       "      <td>415</td>\n",
       "      <td>347-6812</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>106.6</td>\n",
       "      <td>128</td>\n",
       "      <td>18.12</td>\n",
       "      <td>284.8</td>\n",
       "      <td>87</td>\n",
       "      <td>24.21</td>\n",
       "      <td>178.9</td>\n",
       "      <td>92</td>\n",
       "      <td>8.05</td>\n",
       "      <td>14.9</td>\n",
       "      <td>7</td>\n",
       "      <td>4.02</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SC</th>\n",
       "      <td>79</td>\n",
       "      <td>415</td>\n",
       "      <td>348-3830</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>134.7</td>\n",
       "      <td>98</td>\n",
       "      <td>22.90</td>\n",
       "      <td>189.7</td>\n",
       "      <td>68</td>\n",
       "      <td>16.12</td>\n",
       "      <td>221.4</td>\n",
       "      <td>128</td>\n",
       "      <td>9.96</td>\n",
       "      <td>11.8</td>\n",
       "      <td>5</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>192</td>\n",
       "      <td>415</td>\n",
       "      <td>414-4276</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>36</td>\n",
       "      <td>156.2</td>\n",
       "      <td>77</td>\n",
       "      <td>26.55</td>\n",
       "      <td>215.5</td>\n",
       "      <td>126</td>\n",
       "      <td>18.32</td>\n",
       "      <td>279.1</td>\n",
       "      <td>83</td>\n",
       "      <td>12.56</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WV</th>\n",
       "      <td>68</td>\n",
       "      <td>415</td>\n",
       "      <td>370-3271</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>231.1</td>\n",
       "      <td>57</td>\n",
       "      <td>39.29</td>\n",
       "      <td>153.4</td>\n",
       "      <td>55</td>\n",
       "      <td>13.04</td>\n",
       "      <td>191.3</td>\n",
       "      <td>123</td>\n",
       "      <td>8.61</td>\n",
       "      <td>9.6</td>\n",
       "      <td>4</td>\n",
       "      <td>2.59</td>\n",
       "      <td>3</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RI</th>\n",
       "      <td>28</td>\n",
       "      <td>510</td>\n",
       "      <td>328-8230</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>180.8</td>\n",
       "      <td>109</td>\n",
       "      <td>30.74</td>\n",
       "      <td>288.8</td>\n",
       "      <td>58</td>\n",
       "      <td>24.55</td>\n",
       "      <td>191.9</td>\n",
       "      <td>91</td>\n",
       "      <td>8.64</td>\n",
       "      <td>14.1</td>\n",
       "      <td>6</td>\n",
       "      <td>3.81</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CT</th>\n",
       "      <td>184</td>\n",
       "      <td>510</td>\n",
       "      <td>364-6381</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>213.8</td>\n",
       "      <td>105</td>\n",
       "      <td>36.35</td>\n",
       "      <td>159.6</td>\n",
       "      <td>84</td>\n",
       "      <td>13.57</td>\n",
       "      <td>139.2</td>\n",
       "      <td>137</td>\n",
       "      <td>6.26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN</th>\n",
       "      <td>74</td>\n",
       "      <td>415</td>\n",
       "      <td>400-4344</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>25</td>\n",
       "      <td>234.4</td>\n",
       "      <td>113</td>\n",
       "      <td>39.85</td>\n",
       "      <td>265.9</td>\n",
       "      <td>82</td>\n",
       "      <td>22.60</td>\n",
       "      <td>241.4</td>\n",
       "      <td>77</td>\n",
       "      <td>10.86</td>\n",
       "      <td>13.7</td>\n",
       "      <td>4</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3333 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     st   acclen     arcode  phnum  intplan   voice  nummailmes   tdmin  \\\n",
       "KS  128      415   382-4657     no      yes      25       265.1     110   \n",
       "OH  107      415   371-7191     no      yes      26       161.6     123   \n",
       "NJ  137      415   358-1921     no       no       0       243.4     114   \n",
       "OH   84      408   375-9999    yes       no       0       299.4      71   \n",
       "OK   75      415   330-6626    yes       no       0       166.7     113   \n",
       "AL  118      510   391-8027    yes       no       0       223.4      98   \n",
       "MA  121      510   355-9993     no      yes      24       218.2      88   \n",
       "MO  147      415   329-9001    yes       no       0       157.0      79   \n",
       "LA  117      408   335-4719     no       no       0       184.5      97   \n",
       "WV  141      415   330-8173    yes      yes      37       258.6      84   \n",
       "IN   65      415   329-6603     no       no       0       129.1     137   \n",
       "RI   74      415   344-9403     no       no       0       187.7     127   \n",
       "IA  168      408   363-1107     no       no       0       128.8      96   \n",
       "MT   95      510   394-8006     no       no       0       156.6      88   \n",
       "IA   62      415   366-9238     no       no       0       120.7      70   \n",
       "NY  161      415   351-7269     no       no       0       332.9      67   \n",
       "ID   85      408   350-8884     no      yes      27       196.4     139   \n",
       "VT   93      510   386-2923     no       no       0       190.7     114   \n",
       "VA   76      510   356-2992     no      yes      33       189.7      66   \n",
       "TX   73      415   373-2782     no       no       0       224.4      90   \n",
       "FL  147      415   396-5800     no       no       0       155.1     117   \n",
       "CO   77      408   393-7984     no       no       0        62.4      89   \n",
       "AZ  130      415   358-1958     no       no       0       183.0     112   \n",
       "SC  111      415   350-2565     no       no       0       110.4     103   \n",
       "VA  132      510   343-4696     no       no       0        81.1      86   \n",
       "NE  174      415   331-3698     no       no       0       124.3      76   \n",
       "WY   57      408   357-3817     no      yes      39       213.0     115   \n",
       "MT   54      408   418-6412     no       no       0       134.3      73   \n",
       "MO   20      415   353-2630     no       no       0       190.0     109   \n",
       "HI   49      510   410-7789     no       no       0       119.3     117   \n",
       "..  ...      ...        ...    ...      ...     ...         ...     ...   \n",
       "WI  114      415   373-7308     no      yes      26       137.1      88   \n",
       "IL   71      510   330-7137    yes       no       0       186.1     114   \n",
       "IN   58      415   406-8445     no      yes      22       224.1     127   \n",
       "AL  106      408   404-5283     no      yes      29        83.6     131   \n",
       "OK  172      408   398-3632     no       no       0       203.9     109   \n",
       "IA   45      415   399-5763     no       no       0       211.3      87   \n",
       "VT  100      408   340-9449    yes       no       0       219.4     112   \n",
       "NY   94      415   363-1123     no       no       0       190.4      91   \n",
       "LA  128      415   361-2170     no       no       0       147.7      94   \n",
       "SC  181      408   406-6304     no       no       0       229.9     130   \n",
       "ID  127      408   392-5090     no       no       0       102.8     128   \n",
       "MO   89      415   373-7713     no       no       0       178.7      81   \n",
       "ME  149      415   392-1376     no      yes      18       148.5     106   \n",
       "MS  103      510   390-6388     no      yes      29       164.1     111   \n",
       "SD  163      415   379-7290    yes       no       0       197.2      90   \n",
       "OK   52      415   397-9928     no       no       0       124.9     131   \n",
       "WY   89      415   378-6924     no       no       0       115.4      99   \n",
       "GA  122      510   411-5677    yes       no       0       140.0     101   \n",
       "VT   60      415   400-2738     no       no       0       193.9     118   \n",
       "MD   62      408   409-1856     no       no       0       321.1     105   \n",
       "IN  117      415   362-5899     no       no       0       118.4     126   \n",
       "WV  159      415   377-1164     no       no       0       169.8     114   \n",
       "OH   78      408   368-8555     no       no       0       193.4      99   \n",
       "OH   96      415   347-6812     no       no       0       106.6     128   \n",
       "SC   79      415   348-3830     no       no       0       134.7      98   \n",
       "AZ  192      415   414-4276     no      yes      36       156.2      77   \n",
       "WV   68      415   370-3271     no       no       0       231.1      57   \n",
       "RI   28      510   328-8230     no       no       0       180.8     109   \n",
       "CT  184      510   364-6381    yes       no       0       213.8     105   \n",
       "TN   74      415   400-4344     no      yes      25       234.4     113   \n",
       "\n",
       "     tdcal   tdchar   temin   tecal   tecahr   tnmin   tn cal   tnchar  \\\n",
       "KS   45.07    197.4      99   16.78    244.7      91    11.01     10.0   \n",
       "OH   27.47    195.5     103   16.62    254.4     103    11.45     13.7   \n",
       "NJ   41.38    121.2     110   10.30    162.6     104     7.32     12.2   \n",
       "OH   50.90     61.9      88    5.26    196.9      89     8.86      6.6   \n",
       "OK   28.34    148.3     122   12.61    186.9     121     8.41     10.1   \n",
       "AL   37.98    220.6     101   18.75    203.9     118     9.18      6.3   \n",
       "MA   37.09    348.5     108   29.62    212.6     118     9.57      7.5   \n",
       "MO   26.69    103.1      94    8.76    211.8      96     9.53      7.1   \n",
       "LA   31.37    351.6      80   29.89    215.8      90     9.71      8.7   \n",
       "WV   43.96    222.0     111   18.87    326.4      97    14.69     11.2   \n",
       "IN   21.95    228.5      83   19.42    208.8     111     9.40     12.7   \n",
       "RI   31.91    163.4     148   13.89    196.0      94     8.82      9.1   \n",
       "IA   21.90    104.9      71    8.92    141.1     128     6.35     11.2   \n",
       "MT   26.62    247.6      75   21.05    192.3     115     8.65     12.3   \n",
       "IA   20.52    307.2      76   26.11    203.0      99     9.14     13.1   \n",
       "NY   56.59    317.8      97   27.01    160.6     128     7.23      5.4   \n",
       "ID   33.39    280.9      90   23.88     89.3      75     4.02     13.8   \n",
       "VT   32.42    218.2     111   18.55    129.6     121     5.83      8.1   \n",
       "VA   32.25    212.8      65   18.09    165.7     108     7.46     10.0   \n",
       "TX   38.15    159.5      88   13.56    192.8      74     8.68     13.0   \n",
       "FL   26.37    239.7      93   20.37    208.8     133     9.40     10.6   \n",
       "CO   10.61    169.9     121   14.44    209.6      64     9.43      5.7   \n",
       "AZ   31.11     72.9      99    6.20    181.8      78     8.18      9.5   \n",
       "SC   18.77    137.3     102   11.67    189.6     105     8.53      7.7   \n",
       "VA   13.79    245.2      72   20.84    237.0     115    10.67     10.3   \n",
       "NE   21.13    277.1     112   23.55    250.7     115    11.28     15.5   \n",
       "WY   36.21    191.1     112   16.24    182.7     115     8.22      9.5   \n",
       "MT   22.83    155.5     100   13.22    102.1      68     4.59     14.7   \n",
       "MO   32.30    258.2      84   21.95    181.5     102     8.17      6.3   \n",
       "HI   20.28    215.1     109   18.28    178.7      90     8.04     11.1   \n",
       "..     ...      ...     ...     ...      ...     ...      ...      ...   \n",
       "WI   23.31    155.7     125   13.23    247.6      94    11.14     11.5   \n",
       "IL   31.64    198.6     140   16.88    206.5      80     9.29     13.8   \n",
       "IN   38.10    238.8      85   20.30    174.2      86     7.84     11.5   \n",
       "AL   14.21    203.9     131   17.33    229.5      73    10.33      8.1   \n",
       "OK   34.66    234.0     123   19.89    160.7      65     7.23     17.8   \n",
       "IA   35.92    165.7      97   14.08    265.9      72    11.97     13.3   \n",
       "VT   37.30    225.7     102   19.18    255.3      95    11.49     12.0   \n",
       "NY   32.37     92.0     107    7.82    224.8     108    10.12     13.6   \n",
       "LA   25.11    283.3      83   24.08    188.3     124     8.47      6.9   \n",
       "SC   39.08    144.4      93   12.27    262.4     110    11.81     14.2   \n",
       "ID   17.48    143.7      95   12.21    191.4      97     8.61     10.0   \n",
       "MO   30.38    233.7      74   19.86    131.9     120     5.94      9.1   \n",
       "ME   25.25    114.5     106    9.73    178.3      98     8.02      6.5   \n",
       "MS   27.90    219.1      96   18.62    220.3     108     9.91     12.3   \n",
       "SD   33.52    188.5     113   16.02    211.1      94     9.50      7.8   \n",
       "OK   21.23    300.5     118   25.54    192.5     106     8.66     11.6   \n",
       "WY   19.62    209.9     115   17.84    280.9     112    12.64     15.9   \n",
       "GA   23.80    196.4      77   16.69    120.1     133     5.40      9.7   \n",
       "VT   32.96     85.0     110    7.23    210.1     134     9.45     13.2   \n",
       "MD   54.59    265.5     122   22.57    180.5      72     8.12     11.5   \n",
       "IN   20.13    249.3      97   21.19    227.0      56    10.22     13.6   \n",
       "WV   28.87    197.7     105   16.80    193.7      82     8.72     11.6   \n",
       "OH   32.88    116.9      88    9.94    243.3     109    10.95      9.3   \n",
       "OH   18.12    284.8      87   24.21    178.9      92     8.05     14.9   \n",
       "SC   22.90    189.7      68   16.12    221.4     128     9.96     11.8   \n",
       "AZ   26.55    215.5     126   18.32    279.1      83    12.56      9.9   \n",
       "WV   39.29    153.4      55   13.04    191.3     123     8.61      9.6   \n",
       "RI   30.74    288.8      58   24.55    191.9      91     8.64     14.1   \n",
       "CT   36.35    159.6      84   13.57    139.2     137     6.26      5.0   \n",
       "TN   39.85    265.9      82   22.60    241.4      77    10.86     13.7   \n",
       "\n",
       "     timin   tical   tichar ncsc    label  \n",
       "KS       3    2.70             1   False.  \n",
       "OH       3    3.70             1   False.  \n",
       "NJ       5    3.29             0   False.  \n",
       "OH       7    1.78             2   False.  \n",
       "OK       3    2.73             3   False.  \n",
       "AL       6    1.70             0   False.  \n",
       "MA       7    2.03             3   False.  \n",
       "MO       6    1.92             0   False.  \n",
       "LA       4    2.35             1   False.  \n",
       "WV       5    3.02             0   False.  \n",
       "IN       6    3.43             4    True.  \n",
       "RI       5    2.46             0   False.  \n",
       "IA       2    3.02             1   False.  \n",
       "MT       5    3.32             3   False.  \n",
       "IA       6    3.54             4   False.  \n",
       "NY       9    1.46             4    True.  \n",
       "ID       4    3.73             1   False.  \n",
       "VT       3    2.19             3   False.  \n",
       "VA       5    2.70             1   False.  \n",
       "TX       2    3.51             1   False.  \n",
       "FL       4    2.86             0   False.  \n",
       "CO       6    1.54             5    True.  \n",
       "AZ      19    2.57             0   False.  \n",
       "SC       6    2.08             2   False.  \n",
       "VA       2    2.78             0   False.  \n",
       "NE       5    4.19             3   False.  \n",
       "WY       3    2.57             0   False.  \n",
       "MT       4    3.97             3   False.  \n",
       "MO       6    1.70             0   False.  \n",
       "HI       1    3.00             1   False.  \n",
       "..     ...     ...           ...      ...  \n",
       "WI       7    3.11             2   False.  \n",
       "IL       5    3.73             4    True.  \n",
       "IN       7    3.11             2   False.  \n",
       "AL       3    2.19             1   False.  \n",
       "OK       4    4.81             4   False.  \n",
       "IA       6    3.59             1   False.  \n",
       "VT       4    3.24             4   False.  \n",
       "NY      17    3.67             2   False.  \n",
       "LA       5    1.86             2   False.  \n",
       "SC       4    3.83             2   False.  \n",
       "ID       5    2.70             1   False.  \n",
       "MO       4    2.46             1   False.  \n",
       "ME       4    1.76             0   False.  \n",
       "MS       9    3.32             0   False.  \n",
       "SD       8    2.11             1   False.  \n",
       "OK       4    3.13             2   False.  \n",
       "WY       6    4.29             3   False.  \n",
       "GA       4    2.62             4    True.  \n",
       "VT       8    3.56             3   False.  \n",
       "MD       2    3.11             4    True.  \n",
       "IN       3    3.67             5    True.  \n",
       "WV       4    3.13             1   False.  \n",
       "OH       4    2.51             2   False.  \n",
       "OH       7    4.02             1   False.  \n",
       "SC       5    3.19             2   False.  \n",
       "AZ       6    2.67             2   False.  \n",
       "WV       4    2.59             3   False.  \n",
       "RI       6    3.81             2   False.  \n",
       "CT      10    1.35             2   False.  \n",
       "TN       4    3.70             0   False.  \n",
       "\n",
       "[3333 rows x 20 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[128, 415, ' no', ..., 3, 2.7, 1],\n",
       "       [107, 415, ' no', ..., 3, 3.7, 1],\n",
       "       [137, 415, ' no', ..., 5, 3.29, 0],\n",
       "       ...,\n",
       "       [28, 510, ' no', ..., 6, 3.81, 2],\n",
       "       [184, 510, ' yes', ..., 10, 1.35, 2],\n",
       "       [74, 415, ' no', ..., 4, 3.7, 0]], dtype=object)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "labelencoder_X_3 = LabelEncoder()\n",
    "X[:, 3] = labelencoder_X_3.fit_transform(X[:, 3])\n",
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_y.fit_transform(y)\n",
    "#label encoder is enough as we have binary variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3333, 18)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[128, 415, 0, ..., 3, 2.7, 1],\n",
       "       [107, 415, 0, ..., 3, 3.7, 1],\n",
       "       [137, 415, 0, ..., 5, 3.29, 0],\n",
       "       ...,\n",
       "       [28, 510, 0, ..., 6, 3.81, 2],\n",
       "       [184, 510, 1, ..., 10, 1.35, 2],\n",
       "       [74, 415, 0, ..., 4, 3.7, 0]], dtype=object)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chall\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2 -  making the ANN!\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "import sys\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chall\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=18, units=10, kernel_initializer=\"glorot_uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\chall\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=12, kernel_initializer=\"glorot_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\chall\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=14, kernel_initializer=\"glorot_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\chall\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"glorot_uniform\")`\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim = 10, init = 'glorot_uniform', activation = 'relu', input_dim = 18))#1st hidden layer\n",
    "classifier.add(Dropout(0.4, noise_shape=None, seed=None))#dropout regularisation\n",
    "classifier.add(Dense(output_dim = 12, init = 'glorot_uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(0.2, noise_shape=None, seed=None))\n",
    "classifier.add(Dense(output_dim = 14, init = 'glorot_uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(0.1, noise_shape=None, seed=None))\n",
    "classifier.add(Dense(output_dim = 1, init = 'glorot_uniform', activation = 'sigmoid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout is used to avoid overfitting.As we go on with the hidden layers, The information becomes more and more important so I have reduced dropout fraction accordinlgy to fit under fitting ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chall\\Anaconda3\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2666/2666 [==============================] - 1s 191us/step - loss: 0.5299 - acc: 0.8136\n",
      "Epoch 2/100\n",
      "2666/2666 [==============================] - 0s 56us/step - loss: 0.4574 - acc: 0.8503\n",
      "Epoch 3/100\n",
      "2666/2666 [==============================] - 0s 53us/step - loss: 0.4381 - acc: 0.8530\n",
      "Epoch 4/100\n",
      "2666/2666 [==============================] - 0s 54us/step - loss: 0.4134 - acc: 0.8518\n",
      "Epoch 5/100\n",
      "2666/2666 [==============================] - 0s 53us/step - loss: 0.3915 - acc: 0.8530\n",
      "Epoch 6/100\n",
      "2666/2666 [==============================] - 0s 51us/step - loss: 0.3874 - acc: 0.8563\n",
      "Epoch 7/100\n",
      "2666/2666 [==============================] - 0s 53us/step - loss: 0.3805 - acc: 0.8552\n",
      "Epoch 8/100\n",
      "2666/2666 [==============================] - 0s 53us/step - loss: 0.3725 - acc: 0.8578\n",
      "Epoch 9/100\n",
      "2666/2666 [==============================] - 0s 52us/step - loss: 0.3713 - acc: 0.8582\n",
      "Epoch 10/100\n",
      "2666/2666 [==============================] - 0s 53us/step - loss: 0.3559 - acc: 0.8601\n",
      "Epoch 11/100\n",
      "2666/2666 [==============================] - 0s 52us/step - loss: 0.3566 - acc: 0.8650\n",
      "Epoch 12/100\n",
      "2666/2666 [==============================] - 0s 52us/step - loss: 0.3622 - acc: 0.8665\n",
      "Epoch 13/100\n",
      "2666/2666 [==============================] - 0s 52us/step - loss: 0.3521 - acc: 0.8725\n",
      "Epoch 14/100\n",
      "2666/2666 [==============================] - 0s 53us/step - loss: 0.3425 - acc: 0.8713\n",
      "Epoch 15/100\n",
      "2666/2666 [==============================] - 0s 53us/step - loss: 0.3372 - acc: 0.8785\n",
      "Epoch 16/100\n",
      "2666/2666 [==============================] - 0s 53us/step - loss: 0.3306 - acc: 0.8785\n",
      "Epoch 17/100\n",
      "2666/2666 [==============================] - 0s 52us/step - loss: 0.3393 - acc: 0.8758\n",
      "Epoch 18/100\n",
      "2666/2666 [==============================] - 0s 50us/step - loss: 0.3300 - acc: 0.8755\n",
      "Epoch 19/100\n",
      "2666/2666 [==============================] - 0s 51us/step - loss: 0.3395 - acc: 0.8792\n",
      "Epoch 20/100\n",
      "2666/2666 [==============================] - 0s 51us/step - loss: 0.3269 - acc: 0.8796\n",
      "Epoch 21/100\n",
      "2666/2666 [==============================] - 0s 51us/step - loss: 0.3232 - acc: 0.8826\n",
      "Epoch 22/100\n",
      "2666/2666 [==============================] - 0s 52us/step - loss: 0.3106 - acc: 0.8856\n",
      "Epoch 23/100\n",
      "2666/2666 [==============================] - 0s 51us/step - loss: 0.3170 - acc: 0.8841\n",
      "Epoch 24/100\n",
      "2666/2666 [==============================] - 0s 52us/step - loss: 0.3169 - acc: 0.8852\n",
      "Epoch 25/100\n",
      "2666/2666 [==============================] - 0s 53us/step - loss: 0.3116 - acc: 0.8863\n",
      "Epoch 26/100\n",
      "2666/2666 [==============================] - 0s 52us/step - loss: 0.3167 - acc: 0.8852\n",
      "Epoch 27/100\n",
      "2666/2666 [==============================] - 0s 52us/step - loss: 0.3035 - acc: 0.8837\n",
      "Epoch 28/100\n",
      "2666/2666 [==============================] - 0s 50us/step - loss: 0.3068 - acc: 0.8886\n",
      "Epoch 29/100\n",
      "2666/2666 [==============================] - 0s 51us/step - loss: 0.3058 - acc: 0.8905\n",
      "Epoch 30/100\n",
      "2666/2666 [==============================] - 0s 52us/step - loss: 0.3050 - acc: 0.8882\n",
      "Epoch 31/100\n",
      "2666/2666 [==============================] - 0s 51us/step - loss: 0.3074 - acc: 0.8856\n",
      "Epoch 32/100\n",
      "2666/2666 [==============================] - 0s 51us/step - loss: 0.3076 - acc: 0.8860\n",
      "Epoch 33/100\n",
      "2666/2666 [==============================] - 0s 51us/step - loss: 0.3003 - acc: 0.8905\n",
      "Epoch 34/100\n",
      "2666/2666 [==============================] - 0s 51us/step - loss: 0.3075 - acc: 0.8833\n",
      "Epoch 35/100\n",
      "2666/2666 [==============================] - 0s 50us/step - loss: 0.3014 - acc: 0.8965\n",
      "Epoch 36/100\n",
      "2666/2666 [==============================] - 0s 51us/step - loss: 0.3100 - acc: 0.8852\n",
      "Epoch 37/100\n",
      "2666/2666 [==============================] - 0s 51us/step - loss: 0.3052 - acc: 0.8905\n",
      "Epoch 38/100\n",
      "2666/2666 [==============================] - 0s 52us/step - loss: 0.2997 - acc: 0.8901\n",
      "Epoch 39/100\n",
      "2666/2666 [==============================] - 0s 51us/step - loss: 0.3061 - acc: 0.8878\n",
      "Epoch 40/100\n",
      "2666/2666 [==============================] - 0s 51us/step - loss: 0.2937 - acc: 0.8916\n",
      "Epoch 41/100\n",
      "2666/2666 [==============================] - 0s 50us/step - loss: 0.2962 - acc: 0.8980\n",
      "Epoch 42/100\n",
      "2666/2666 [==============================] - 0s 50us/step - loss: 0.2903 - acc: 0.9017\n",
      "Epoch 43/100\n",
      "2666/2666 [==============================] - 0s 52us/step - loss: 0.3010 - acc: 0.8920\n",
      "Epoch 44/100\n",
      "2666/2666 [==============================] - 0s 50us/step - loss: 0.2983 - acc: 0.8957\n",
      "Epoch 45/100\n",
      "2666/2666 [==============================] - 0s 52us/step - loss: 0.2826 - acc: 0.9014\n",
      "Epoch 46/100\n",
      "2666/2666 [==============================] - 0s 55us/step - loss: 0.2958 - acc: 0.8961\n",
      "Epoch 47/100\n",
      "2666/2666 [==============================] - 0s 52us/step - loss: 0.2899 - acc: 0.8961\n",
      "Epoch 48/100\n",
      "2666/2666 [==============================] - 0s 60us/step - loss: 0.3080 - acc: 0.8890\n",
      "Epoch 49/100\n",
      "2666/2666 [==============================] - 0s 52us/step - loss: 0.2862 - acc: 0.9010\n",
      "Epoch 50/100\n",
      "2666/2666 [==============================] - 0s 59us/step - loss: 0.2874 - acc: 0.8987\n",
      "Epoch 51/100\n",
      "2666/2666 [==============================] - 0s 53us/step - loss: 0.2843 - acc: 0.8998\n",
      "Epoch 52/100\n",
      "2666/2666 [==============================] - 0s 58us/step - loss: 0.3023 - acc: 0.8938\n",
      "Epoch 53/100\n",
      "2666/2666 [==============================] - 0s 54us/step - loss: 0.2942 - acc: 0.8938\n",
      "Epoch 54/100\n",
      "2666/2666 [==============================] - 0s 53us/step - loss: 0.2918 - acc: 0.9017\n",
      "Epoch 55/100\n",
      "2666/2666 [==============================] - 0s 51us/step - loss: 0.2961 - acc: 0.8916\n",
      "Epoch 56/100\n",
      "2666/2666 [==============================] - 0s 54us/step - loss: 0.2935 - acc: 0.8976\n",
      "Epoch 57/100\n",
      "2666/2666 [==============================] - 0s 53us/step - loss: 0.3040 - acc: 0.8875\n",
      "Epoch 58/100\n",
      "2666/2666 [==============================] - 0s 51us/step - loss: 0.2887 - acc: 0.8980\n",
      "Epoch 59/100\n",
      "2666/2666 [==============================] - 0s 51us/step - loss: 0.2907 - acc: 0.8965\n",
      "Epoch 60/100\n",
      "2666/2666 [==============================] - 0s 52us/step - loss: 0.2847 - acc: 0.9006\n",
      "Epoch 61/100\n",
      "2666/2666 [==============================] - 0s 54us/step - loss: 0.2847 - acc: 0.8995\n",
      "Epoch 62/100\n",
      "2666/2666 [==============================] - 0s 55us/step - loss: 0.2854 - acc: 0.8972\n",
      "Epoch 63/100\n",
      "2666/2666 [==============================] - 0s 68us/step - loss: 0.2906 - acc: 0.9002\n",
      "Epoch 64/100\n",
      "2666/2666 [==============================] - 0s 65us/step - loss: 0.2828 - acc: 0.9014\n",
      "Epoch 65/100\n",
      "2666/2666 [==============================] - 0s 68us/step - loss: 0.2873 - acc: 0.8965\n",
      "Epoch 66/100\n",
      "2666/2666 [==============================] - 0s 63us/step - loss: 0.2902 - acc: 0.8946\n",
      "Epoch 67/100\n",
      "2666/2666 [==============================] - 0s 52us/step - loss: 0.2864 - acc: 0.9002\n",
      "Epoch 68/100\n",
      "2666/2666 [==============================] - 0s 50us/step - loss: 0.2825 - acc: 0.8965\n",
      "Epoch 69/100\n",
      "2666/2666 [==============================] - 0s 53us/step - loss: 0.2947 - acc: 0.8965\n",
      "Epoch 70/100\n",
      "2666/2666 [==============================] - 0s 60us/step - loss: 0.2858 - acc: 0.9032\n",
      "Epoch 71/100\n",
      "2666/2666 [==============================] - 0s 60us/step - loss: 0.2928 - acc: 0.8931\n",
      "Epoch 72/100\n",
      "2666/2666 [==============================] - 0s 62us/step - loss: 0.2800 - acc: 0.8983\n",
      "Epoch 73/100\n",
      "2666/2666 [==============================] - 0s 64us/step - loss: 0.2800 - acc: 0.9051\n",
      "Epoch 74/100\n",
      "2666/2666 [==============================] - 0s 54us/step - loss: 0.2873 - acc: 0.8991\n",
      "Epoch 75/100\n",
      "2666/2666 [==============================] - 0s 55us/step - loss: 0.2824 - acc: 0.9029\n",
      "Epoch 76/100\n",
      "2666/2666 [==============================] - 0s 56us/step - loss: 0.2790 - acc: 0.9062\n",
      "Epoch 77/100\n",
      "2666/2666 [==============================] - 0s 61us/step - loss: 0.2802 - acc: 0.9014\n",
      "Epoch 78/100\n",
      "2666/2666 [==============================] - 0s 53us/step - loss: 0.2858 - acc: 0.8976\n",
      "Epoch 79/100\n",
      "2666/2666 [==============================] - 0s 52us/step - loss: 0.2743 - acc: 0.9051\n",
      "Epoch 80/100\n",
      "2666/2666 [==============================] - 0s 59us/step - loss: 0.2870 - acc: 0.8998\n",
      "Epoch 81/100\n",
      "2666/2666 [==============================] - 0s 62us/step - loss: 0.2781 - acc: 0.9044\n",
      "Epoch 82/100\n",
      "2666/2666 [==============================] - 0s 56us/step - loss: 0.2838 - acc: 0.9014\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2666/2666 [==============================] - 0s 51us/step - loss: 0.2913 - acc: 0.8965\n",
      "Epoch 84/100\n",
      "2666/2666 [==============================] - 0s 50us/step - loss: 0.2755 - acc: 0.9014\n",
      "Epoch 85/100\n",
      "2666/2666 [==============================] - 0s 53us/step - loss: 0.2901 - acc: 0.8950\n",
      "Epoch 86/100\n",
      "2666/2666 [==============================] - 0s 58us/step - loss: 0.2862 - acc: 0.8976\n",
      "Epoch 87/100\n",
      "2666/2666 [==============================] - 0s 59us/step - loss: 0.2759 - acc: 0.9032\n",
      "Epoch 88/100\n",
      "2666/2666 [==============================] - 0s 52us/step - loss: 0.2853 - acc: 0.8983\n",
      "Epoch 89/100\n",
      "2666/2666 [==============================] - 0s 51us/step - loss: 0.2777 - acc: 0.9006\n",
      "Epoch 90/100\n",
      "2666/2666 [==============================] - 0s 51us/step - loss: 0.2890 - acc: 0.8983\n",
      "Epoch 91/100\n",
      "2666/2666 [==============================] - 0s 52us/step - loss: 0.2760 - acc: 0.9032\n",
      "Epoch 92/100\n",
      "2666/2666 [==============================] - 0s 50us/step - loss: 0.2849 - acc: 0.8983\n",
      "Epoch 93/100\n",
      "2666/2666 [==============================] - 0s 52us/step - loss: 0.2818 - acc: 0.8991\n",
      "Epoch 94/100\n",
      "2666/2666 [==============================] - 0s 52us/step - loss: 0.2860 - acc: 0.9006\n",
      "Epoch 95/100\n",
      "2666/2666 [==============================] - 0s 51us/step - loss: 0.2840 - acc: 0.9014\n",
      "Epoch 96/100\n",
      "2666/2666 [==============================] - 0s 52us/step - loss: 0.2820 - acc: 0.9014\n",
      "Epoch 97/100\n",
      "2666/2666 [==============================] - 0s 56us/step - loss: 0.2896 - acc: 0.8961\n",
      "Epoch 98/100\n",
      "2666/2666 [==============================] - 0s 58us/step - loss: 0.2662 - acc: 0.9092\n",
      "Epoch 99/100\n",
      "2666/2666 [==============================] - 0s 50us/step - loss: 0.2871 - acc: 0.8998\n",
      "Epoch 100/100\n",
      "2666/2666 [==============================] - 0s 52us/step - loss: 0.2779 - acc: 0.9036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227e8b03940>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 25, nb_epoch = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Part 3 - Making the predictions and evaluating the model\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[579,   0],\n",
       "       [ 67,  21]])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting with the complete dataset and predicting the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('churn_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_out = data_test.iloc[:, [0,1,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]].values\n",
    "y_test_out = data_test.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1667, 18)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[101, 510, ' no', ..., 3, 2.86, 3],\n",
       "       [137, 510, ' no', ..., 7, 2.57, 0],\n",
       "       [103, 408, ' no', ..., 6, 3.7, 1],\n",
       "       ...,\n",
       "       [61, 415, ' no', ..., 4, 3.67, 1],\n",
       "       [109, 510, ' no', ..., 6, 2.3, 0],\n",
       "       [86, 415, ' no', ..., 16, 2.51, 0]], dtype=object)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' False.', ' False.', ' False.', ..., ' False.', ' False.',\n",
       "       ' False.'], dtype=object)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_out[:,3] = labelencoder_X_3.transform(X_test_out[:,3])\n",
    "X_test_out[:,2] = labelencoder_X_2.transform(X_test_out[:,2])\n",
    "y_test_out = labelencoder_y.transform(y_test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_totalt = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3333/3333 [==============================] - 0s 58us/step - loss: 5.6187 - acc: 0.6427\n",
      "Epoch 2/100\n",
      "  25/3333 [..............................] - ETA: 0s - loss: 7.6875 - acc: 0.5200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chall\\Anaconda3\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3333/3333 [==============================] - 0s 58us/step - loss: 3.6075 - acc: 0.7714\n",
      "Epoch 3/100\n",
      "3333/3333 [==============================] - 0s 55us/step - loss: 2.9747 - acc: 0.8098\n",
      "Epoch 4/100\n",
      "3333/3333 [==============================] - 0s 57us/step - loss: 2.7956 - acc: 0.8227\n",
      "Epoch 5/100\n",
      "3333/3333 [==============================] - 0s 58us/step - loss: 2.6715 - acc: 0.8296\n",
      "Epoch 6/100\n",
      "3333/3333 [==============================] - 0s 57us/step - loss: 2.6996 - acc: 0.8284\n",
      "Epoch 7/100\n",
      "3333/3333 [==============================] - 0s 54us/step - loss: 2.6971 - acc: 0.8293\n",
      "Epoch 8/100\n",
      "3333/3333 [==============================] - 0s 57us/step - loss: 2.5753 - acc: 0.8359\n",
      "Epoch 9/100\n",
      "3333/3333 [==============================] - 0s 65us/step - loss: 2.5639 - acc: 0.8374\n",
      "Epoch 10/100\n",
      "3333/3333 [==============================] - 0s 55us/step - loss: 2.4186 - acc: 0.8437\n",
      "Epoch 11/100\n",
      "3333/3333 [==============================] - 0s 53us/step - loss: 2.2559 - acc: 0.8530\n",
      "Epoch 12/100\n",
      "3333/3333 [==============================] - 0s 54us/step - loss: 2.2472 - acc: 0.8539\n",
      "Epoch 13/100\n",
      "3333/3333 [==============================] - 0s 54us/step - loss: 2.2183 - acc: 0.8545\n",
      "Epoch 14/100\n",
      "3333/3333 [==============================] - 0s 52us/step - loss: 2.2293 - acc: 0.8545\n",
      "Epoch 15/100\n",
      "3333/3333 [==============================] - 0s 63us/step - loss: 2.1608 - acc: 0.8557\n",
      "Epoch 16/100\n",
      "3333/3333 [==============================] - 0s 56us/step - loss: 2.1826 - acc: 0.8560\n",
      "Epoch 17/100\n",
      "3333/3333 [==============================] - 0s 55us/step - loss: 2.2040 - acc: 0.8557\n",
      "Epoch 18/100\n",
      "3333/3333 [==============================] - 0s 64us/step - loss: 2.2015 - acc: 0.8545\n",
      "Epoch 19/100\n",
      "3333/3333 [==============================] - 0s 66us/step - loss: 2.1960 - acc: 0.8551\n",
      "Epoch 20/100\n",
      "3333/3333 [==============================] - 0s 57us/step - loss: 2.2633 - acc: 0.8548\n",
      "Epoch 21/100\n",
      "3333/3333 [==============================] - 0s 57us/step - loss: 2.2294 - acc: 0.8551\n",
      "Epoch 22/100\n",
      "3333/3333 [==============================] - 0s 53us/step - loss: 2.1945 - acc: 0.8557\n",
      "Epoch 23/100\n",
      "3333/3333 [==============================] - 0s 53us/step - loss: 2.1921 - acc: 0.8551\n",
      "Epoch 24/100\n",
      "3333/3333 [==============================] - 0s 52us/step - loss: 2.2619 - acc: 0.8554\n",
      "Epoch 25/100\n",
      "3333/3333 [==============================] - 0s 53us/step - loss: 2.2292 - acc: 0.8554\n",
      "Epoch 26/100\n",
      "3333/3333 [==============================] - 0s 52us/step - loss: 2.2423 - acc: 0.8551\n",
      "Epoch 27/100\n",
      "3333/3333 [==============================] - 0s 52us/step - loss: 2.2082 - acc: 0.8554\n",
      "Epoch 28/100\n",
      "3333/3333 [==============================] - 0s 61us/step - loss: 2.2079 - acc: 0.8554\n",
      "Epoch 29/100\n",
      "3333/3333 [==============================] - 0s 53us/step - loss: 2.2275 - acc: 0.8545\n",
      "Epoch 30/100\n",
      "3333/3333 [==============================] - 0s 63us/step - loss: 2.2038 - acc: 0.8554\n",
      "Epoch 31/100\n",
      "3333/3333 [==============================] - 0s 54us/step - loss: 2.2290 - acc: 0.8554\n",
      "Epoch 32/100\n",
      "3333/3333 [==============================] - 0s 60us/step - loss: 2.1946 - acc: 0.8557\n",
      "Epoch 33/100\n",
      "3333/3333 [==============================] - 0s 55us/step - loss: 2.2420 - acc: 0.8551\n",
      "Epoch 34/100\n",
      "3333/3333 [==============================] - 0s 52us/step - loss: 2.2246 - acc: 0.8557\n",
      "Epoch 35/100\n",
      "3333/3333 [==============================] - 0s 55us/step - loss: 2.1967 - acc: 0.8545\n",
      "Epoch 36/100\n",
      "3333/3333 [==============================] - 0s 50us/step - loss: 2.2180 - acc: 0.8548\n",
      "Epoch 37/100\n",
      "3333/3333 [==============================] - 0s 64us/step - loss: 2.2527 - acc: 0.8560\n",
      "Epoch 38/100\n",
      "3333/3333 [==============================] - 0s 68us/step - loss: 2.1983 - acc: 0.8554\n",
      "Epoch 39/100\n",
      "3333/3333 [==============================] - 0s 73us/step - loss: 2.2262 - acc: 0.8548\n",
      "Epoch 40/100\n",
      "3333/3333 [==============================] - 0s 60us/step - loss: 2.1958 - acc: 0.8554\n",
      "Epoch 41/100\n",
      "3333/3333 [==============================] - 0s 58us/step - loss: 2.1897 - acc: 0.8560\n",
      "Epoch 42/100\n",
      "3333/3333 [==============================] - 0s 59us/step - loss: 2.2022 - acc: 0.8557\n",
      "Epoch 43/100\n",
      "3333/3333 [==============================] - 0s 58us/step - loss: 2.2039 - acc: 0.8554\n",
      "Epoch 44/100\n",
      "3333/3333 [==============================] - 0s 62us/step - loss: 2.2331 - acc: 0.8554\n",
      "Epoch 45/100\n",
      "3333/3333 [==============================] - 0s 69us/step - loss: 2.1866 - acc: 0.8554\n",
      "Epoch 46/100\n",
      "3333/3333 [==============================] - 0s 68us/step - loss: 2.1688 - acc: 0.8551\n",
      "Epoch 47/100\n",
      "3333/3333 [==============================] - 0s 64us/step - loss: 2.2645 - acc: 0.8551\n",
      "Epoch 48/100\n",
      "3333/3333 [==============================] - 0s 59us/step - loss: 2.2165 - acc: 0.8557\n",
      "Epoch 49/100\n",
      "3333/3333 [==============================] - 0s 64us/step - loss: 2.2089 - acc: 0.8551\n",
      "Epoch 50/100\n",
      "3333/3333 [==============================] - 0s 67us/step - loss: 2.1989 - acc: 0.8554\n",
      "Epoch 51/100\n",
      "3333/3333 [==============================] - 0s 60us/step - loss: 2.1987 - acc: 0.8554\n",
      "Epoch 52/100\n",
      "3333/3333 [==============================] - 0s 55us/step - loss: 2.2565 - acc: 0.8551\n",
      "Epoch 53/100\n",
      "3333/3333 [==============================] - 0s 53us/step - loss: 2.2216 - acc: 0.8554\n",
      "Epoch 54/100\n",
      "3333/3333 [==============================] - 0s 52us/step - loss: 2.2222 - acc: 0.8551\n",
      "Epoch 55/100\n",
      "3333/3333 [==============================] - 0s 52us/step - loss: 2.2372 - acc: 0.8554\n",
      "Epoch 56/100\n",
      "3333/3333 [==============================] - 0s 53us/step - loss: 2.2344 - acc: 0.8548\n",
      "Epoch 57/100\n",
      "3333/3333 [==============================] - 0s 53us/step - loss: 2.2127 - acc: 0.8557\n",
      "Epoch 58/100\n",
      "3333/3333 [==============================] - 0s 52us/step - loss: 2.2261 - acc: 0.8554\n",
      "Epoch 59/100\n",
      "3333/3333 [==============================] - 0s 53us/step - loss: 2.2289 - acc: 0.8548\n",
      "Epoch 60/100\n",
      "3333/3333 [==============================] - 0s 52us/step - loss: 2.1938 - acc: 0.8545\n",
      "Epoch 61/100\n",
      "3333/3333 [==============================] - 0s 52us/step - loss: 2.2255 - acc: 0.8554\n",
      "Epoch 62/100\n",
      "3333/3333 [==============================] - 0s 52us/step - loss: 2.2097 - acc: 0.8551\n",
      "Epoch 63/100\n",
      "3333/3333 [==============================] - 0s 53us/step - loss: 2.2172 - acc: 0.8551\n",
      "Epoch 64/100\n",
      "3333/3333 [==============================] - 0s 55us/step - loss: 2.2028 - acc: 0.8554\n",
      "Epoch 65/100\n",
      "3333/3333 [==============================] - 0s 54us/step - loss: 2.2164 - acc: 0.8551\n",
      "Epoch 66/100\n",
      "3333/3333 [==============================] - 0s 54us/step - loss: 2.2118 - acc: 0.8554\n",
      "Epoch 67/100\n",
      "3333/3333 [==============================] - 0s 53us/step - loss: 2.2543 - acc: 0.8551\n",
      "Epoch 68/100\n",
      "3333/3333 [==============================] - 0s 53us/step - loss: 2.1844 - acc: 0.8554\n",
      "Epoch 69/100\n",
      "3333/3333 [==============================] - 0s 54us/step - loss: 2.1921 - acc: 0.8551\n",
      "Epoch 70/100\n",
      "3333/3333 [==============================] - 0s 55us/step - loss: 2.2218 - acc: 0.8554\n",
      "Epoch 71/100\n",
      "3333/3333 [==============================] - 0s 55us/step - loss: 2.1539 - acc: 0.8551\n",
      "Epoch 72/100\n",
      "3333/3333 [==============================] - 0s 55us/step - loss: 2.2388 - acc: 0.8551\n",
      "Epoch 73/100\n",
      "3333/3333 [==============================] - 0s 53us/step - loss: 2.2248 - acc: 0.8554\n",
      "Epoch 74/100\n",
      "3333/3333 [==============================] - 0s 51us/step - loss: 2.2119 - acc: 0.8554\n",
      "Epoch 75/100\n",
      "3333/3333 [==============================] - 0s 52us/step - loss: 2.2246 - acc: 0.8554\n",
      "Epoch 76/100\n",
      "3333/3333 [==============================] - 0s 52us/step - loss: 2.2139 - acc: 0.8548\n",
      "Epoch 77/100\n",
      "3333/3333 [==============================] - 0s 53us/step - loss: 2.2127 - acc: 0.8557\n",
      "Epoch 78/100\n",
      "3333/3333 [==============================] - 0s 51us/step - loss: 2.2096 - acc: 0.8551\n",
      "Epoch 79/100\n",
      "3333/3333 [==============================] - 0s 53us/step - loss: 2.2263 - acc: 0.8551\n",
      "Epoch 80/100\n",
      "3333/3333 [==============================] - 0s 52us/step - loss: 2.2097 - acc: 0.8551\n",
      "Epoch 81/100\n",
      "3333/3333 [==============================] - 0s 53us/step - loss: 2.2038 - acc: 0.8551\n",
      "Epoch 82/100\n",
      "3333/3333 [==============================] - 0s 53us/step - loss: 2.2333 - acc: 0.8551\n",
      "Epoch 83/100\n",
      "3333/3333 [==============================] - 0s 53us/step - loss: 2.2366 - acc: 0.8554\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3333/3333 [==============================] - 0s 52us/step - loss: 2.2251 - acc: 0.8551\n",
      "Epoch 85/100\n",
      "3333/3333 [==============================] - 0s 50us/step - loss: 2.2175 - acc: 0.8548\n",
      "Epoch 86/100\n",
      "3333/3333 [==============================] - 0s 51us/step - loss: 2.2509 - acc: 0.8551\n",
      "Epoch 87/100\n",
      "3333/3333 [==============================] - 0s 50us/step - loss: 2.1926 - acc: 0.8551\n",
      "Epoch 88/100\n",
      "3333/3333 [==============================] - 0s 47us/step - loss: 2.2051 - acc: 0.8551\n",
      "Epoch 89/100\n",
      "3333/3333 [==============================] - 0s 56us/step - loss: 2.2181 - acc: 0.8551\n",
      "Epoch 90/100\n",
      "3333/3333 [==============================] - 0s 49us/step - loss: 2.2094 - acc: 0.8554\n",
      "Epoch 91/100\n",
      "3333/3333 [==============================] - 0s 55us/step - loss: 2.2135 - acc: 0.8551\n",
      "Epoch 92/100\n",
      "3333/3333 [==============================] - 0s 50us/step - loss: 2.2162 - acc: 0.8551\n",
      "Epoch 93/100\n",
      "3333/3333 [==============================] - 0s 54us/step - loss: 2.2107 - acc: 0.8551\n",
      "Epoch 94/100\n",
      "3333/3333 [==============================] - 0s 52us/step - loss: 2.2280 - acc: 0.8554\n",
      "Epoch 95/100\n",
      "3333/3333 [==============================] - 0s 49us/step - loss: 2.1913 - acc: 0.8551\n",
      "Epoch 96/100\n",
      "3333/3333 [==============================] - 0s 55us/step - loss: 2.2108 - acc: 0.8554\n",
      "Epoch 97/100\n",
      "3333/3333 [==============================] - 0s 49us/step - loss: 2.2206 - acc: 0.8551\n",
      "Epoch 98/100\n",
      "3333/3333 [==============================] - 0s 56us/step - loss: 2.1911 - acc: 0.8554\n",
      "Epoch 99/100\n",
      "3333/3333 [==============================] - 0s 55us/step - loss: 2.2268 - acc: 0.8560\n",
      "Epoch 100/100\n",
      "3333/3333 [==============================] - 0s 55us/step - loss: 2.2120 - acc: 0.8554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227e91bd390>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier_totalt.fit(X, y, batch_size = 25, nb_epoch = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Part 3 - Making the predictions and evaluating the model\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred_classifier = classifier.predict(X_test_out)\n",
    "y_pred_classifier = (y_pred_classifier > 0.5)\n",
    "y_pred_totalt = classifier_totalt.predict(X_test_out)\n",
    "y_pred_totalt = (y_pred_totalt > 0.5)\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_out_classifier = confusion_matrix(y_test_out, y_pred_classifier)\n",
    "cm_out_classifier_total = confusion_matrix(y_test_out, y_pred_totalt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1443,    0],\n",
       "       [ 224,    0]])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_out_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1443,    0],\n",
       "       [ 224,    0]])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_out_classifier_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
