{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    " \n",
    "# Image dimensions\n",
    "img_width, img_height = 150, 150 \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(p, input_shape=(32, 32, 3)):\n",
    "    # Initialising the CNN\n",
    "    model = Sequential()\n",
    "    # Convolution + Pooling Layer \n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Convolution + Pooling Layer \n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Convolution  followed by Pooling Layer \n",
    "    # increasing the number of filters as we have pooled out features reduced features. we can afford to apply 64 filters.\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Convolution + Pooling Layer \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Flattening\n",
    "    model.add(Flatten())\n",
    "    # Fully connection ANN\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(p))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(p/2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "        # Compiling the CNN\n",
    "    optimizer = Adam(lr=1e-3)\n",
    "    metrics=['accuracy']\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(bs=32, epochs=10):\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(rescale = 1./255, \n",
    "                                       shear_range = 0.2, \n",
    "                                       zoom_range = 0.2, \n",
    "                                       horizontal_flip = True)\n",
    "    test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    " \n",
    "    training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (img_width, img_height),\n",
    "                                                 batch_size = bs,\n",
    "                                                 class_mode = 'binary')\n",
    "                                                 \n",
    "    test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (img_width, img_height),\n",
    "                                            batch_size = bs,\n",
    "                                            class_mode = 'binary')\n",
    "                                            \n",
    "    model = create_model(p=0.6, input_shape=(img_width, img_height, 3))                                  \n",
    "    model.fit_generator(training_set,\n",
    "                         steps_per_epoch=8000/bs,\n",
    "                         epochs = epochs,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 2000/bs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Epoch 1/100\n",
      "250/250 [==============================] - 340s 1s/step - loss: 0.6896 - acc: 0.5255 - val_loss: 0.6897 - val_acc: 0.5770\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 181s 726ms/step - loss: 0.6935 - acc: 0.5081 - val_loss: 0.6930 - val_acc: 0.5005\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 363s 1s/step - loss: 0.6932 - acc: 0.5052 - val_loss: 0.6891 - val_acc: 0.5090\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 190s 759ms/step - loss: 0.6889 - acc: 0.5275 - val_loss: 0.6895 - val_acc: 0.5000\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 287s 1s/step - loss: 0.6879 - acc: 0.5553 - val_loss: 0.6791 - val_acc: 0.5905\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 187s 749ms/step - loss: 0.6804 - acc: 0.5707 - val_loss: 0.6676 - val_acc: 0.6170\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 182s 729ms/step - loss: 0.6591 - acc: 0.6120 - val_loss: 0.6540 - val_acc: 0.6310\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 288s 1s/step - loss: 0.6397 - acc: 0.6387 - val_loss: 0.5950 - val_acc: 0.7000\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 405s 2s/step - loss: 0.6151 - acc: 0.6707 - val_loss: 0.6062 - val_acc: 0.6865\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 345s 1s/step - loss: 0.5863 - acc: 0.6980 - val_loss: 0.5415 - val_acc: 0.7390\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 381s 2s/step - loss: 0.5667 - acc: 0.7125 - val_loss: 0.5538 - val_acc: 0.7260\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 188s 750ms/step - loss: 0.5517 - acc: 0.7272 - val_loss: 0.5112 - val_acc: 0.7655\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 182s 729ms/step - loss: 0.5430 - acc: 0.7298 - val_loss: 0.5330 - val_acc: 0.7330\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 183s 734ms/step - loss: 0.5306 - acc: 0.7441 - val_loss: 0.5143 - val_acc: 0.7480\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 182s 729ms/step - loss: 0.5203 - acc: 0.7494 - val_loss: 0.4840 - val_acc: 0.7725\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 181s 726ms/step - loss: 0.4973 - acc: 0.7632 - val_loss: 0.4682 - val_acc: 0.7860\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 184s 736ms/step - loss: 0.4962 - acc: 0.7676 - val_loss: 0.4702 - val_acc: 0.7815\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 182s 729ms/step - loss: 0.4910 - acc: 0.7656 - val_loss: 0.4525 - val_acc: 0.8040\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 182s 730ms/step - loss: 0.4873 - acc: 0.7685 - val_loss: 0.4630 - val_acc: 0.7870\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 182s 727ms/step - loss: 0.4746 - acc: 0.7751 - val_loss: 0.4653 - val_acc: 0.7770\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 187s 747ms/step - loss: 0.4559 - acc: 0.7893 - val_loss: 0.4252 - val_acc: 0.8070\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 181s 725ms/step - loss: 0.4525 - acc: 0.7920 - val_loss: 0.4268 - val_acc: 0.8110\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 182s 728ms/step - loss: 0.4484 - acc: 0.7931 - val_loss: 0.4271 - val_acc: 0.8045\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 183s 734ms/step - loss: 0.4351 - acc: 0.7967 - val_loss: 0.4247 - val_acc: 0.8115\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 183s 730ms/step - loss: 0.4220 - acc: 0.8116 - val_loss: 0.4046 - val_acc: 0.8230\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 184s 735ms/step - loss: 0.4184 - acc: 0.8071 - val_loss: 0.4441 - val_acc: 0.7980\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 183s 732ms/step - loss: 0.4046 - acc: 0.8174 - val_loss: 0.4153 - val_acc: 0.8140\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 984s 4s/step - loss: 0.4035 - acc: 0.8191 - val_loss: 0.3933 - val_acc: 0.8280\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 257s 1s/step - loss: 0.3918 - acc: 0.8225 - val_loss: 0.3880 - val_acc: 0.8225\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 205s 820ms/step - loss: 0.3894 - acc: 0.8284 - val_loss: 0.4283 - val_acc: 0.7965\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 194s 776ms/step - loss: 0.3721 - acc: 0.8351 - val_loss: 0.3894 - val_acc: 0.8305\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 197s 789ms/step - loss: 0.3795 - acc: 0.8310 - val_loss: 0.4564 - val_acc: 0.7855\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 202s 810ms/step - loss: 0.3633 - acc: 0.8399 - val_loss: 0.3929 - val_acc: 0.8230\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 187s 748ms/step - loss: 0.3583 - acc: 0.8423 - val_loss: 0.3833 - val_acc: 0.8325\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 191s 764ms/step - loss: 0.3585 - acc: 0.8424 - val_loss: 0.3863 - val_acc: 0.8315\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 186s 743ms/step - loss: 0.3491 - acc: 0.8440 - val_loss: 0.3820 - val_acc: 0.8345\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 193s 770ms/step - loss: 0.3469 - acc: 0.8465 - val_loss: 0.3828 - val_acc: 0.8305\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 192s 768ms/step - loss: 0.3370 - acc: 0.8536 - val_loss: 0.3654 - val_acc: 0.8430\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 194s 775ms/step - loss: 0.3254 - acc: 0.8606 - val_loss: 0.3449 - val_acc: 0.8450\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 188s 751ms/step - loss: 0.3178 - acc: 0.8655 - val_loss: 0.3531 - val_acc: 0.8500\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 191s 764ms/step - loss: 0.3273 - acc: 0.8622 - val_loss: 0.3749 - val_acc: 0.8415\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 191s 762ms/step - loss: 0.3180 - acc: 0.8650 - val_loss: 0.3494 - val_acc: 0.8465\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 192s 769ms/step - loss: 0.3220 - acc: 0.8646 - val_loss: 0.3424 - val_acc: 0.8620\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 190s 759ms/step - loss: 0.3130 - acc: 0.8645 - val_loss: 0.3535 - val_acc: 0.8540\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 195s 782ms/step - loss: 0.3132 - acc: 0.8665 - val_loss: 0.3598 - val_acc: 0.8495\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 190s 760ms/step - loss: 0.2961 - acc: 0.8699 - val_loss: 0.3648 - val_acc: 0.8365\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 188s 752ms/step - loss: 0.2978 - acc: 0.8739 - val_loss: 0.3397 - val_acc: 0.8480\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 192s 768ms/step - loss: 0.2952 - acc: 0.8784 - val_loss: 0.3509 - val_acc: 0.8450\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 186s 746ms/step - loss: 0.2824 - acc: 0.8816 - val_loss: 0.3450 - val_acc: 0.8445\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 187s 748ms/step - loss: 0.2870 - acc: 0.8794 - val_loss: 0.3652 - val_acc: 0.8390\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 191s 762ms/step - loss: 0.2790 - acc: 0.8834 - val_loss: 0.3339 - val_acc: 0.8550\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 190s 762ms/step - loss: 0.2807 - acc: 0.8805 - val_loss: 0.3164 - val_acc: 0.8680\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 186s 745ms/step - loss: 0.2810 - acc: 0.8802 - val_loss: 0.3470 - val_acc: 0.8475\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 189s 758ms/step - loss: 0.2777 - acc: 0.8821 - val_loss: 0.3280 - val_acc: 0.8565\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 187s 746ms/step - loss: 0.2759 - acc: 0.8805 - val_loss: 0.3348 - val_acc: 0.8570\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 187s 748ms/step - loss: 0.2682 - acc: 0.8840 - val_loss: 0.3533 - val_acc: 0.8415\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 188s 753ms/step - loss: 0.2543 - acc: 0.8919 - val_loss: 0.3300 - val_acc: 0.8580\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 190s 761ms/step - loss: 0.2580 - acc: 0.8889 - val_loss: 0.3423 - val_acc: 0.8540\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 187s 747ms/step - loss: 0.2644 - acc: 0.8900 - val_loss: 0.3330 - val_acc: 0.8515\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 187s 749ms/step - loss: 0.2523 - acc: 0.8951 - val_loss: 0.3389 - val_acc: 0.8530\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 188s 752ms/step - loss: 0.2590 - acc: 0.8899 - val_loss: 0.3372 - val_acc: 0.8565\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 189s 754ms/step - loss: 0.2389 - acc: 0.8979 - val_loss: 0.3432 - val_acc: 0.8535\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 184s 738ms/step - loss: 0.2473 - acc: 0.8984 - val_loss: 0.3307 - val_acc: 0.8510\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 184s 737ms/step - loss: 0.2402 - acc: 0.9001 - val_loss: 0.3030 - val_acc: 0.8665\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 186s 745ms/step - loss: 0.2448 - acc: 0.9002 - val_loss: 0.3361 - val_acc: 0.8615\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 188s 750ms/step - loss: 0.2457 - acc: 0.8980 - val_loss: 0.3162 - val_acc: 0.8590\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 184s 736ms/step - loss: 0.2323 - acc: 0.8992 - val_loss: 0.3279 - val_acc: 0.8605\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 185s 741ms/step - loss: 0.2407 - acc: 0.8973 - val_loss: 0.3285 - val_acc: 0.8535\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 185s 739ms/step - loss: 0.2337 - acc: 0.9022 - val_loss: 0.3103 - val_acc: 0.8735\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 186s 743ms/step - loss: 0.2340 - acc: 0.9015 - val_loss: 0.3225 - val_acc: 0.8495\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 191s 763ms/step - loss: 0.2296 - acc: 0.9039 - val_loss: 0.3281 - val_acc: 0.8540\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 185s 740ms/step - loss: 0.2237 - acc: 0.9048 - val_loss: 0.2885 - val_acc: 0.8735\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 186s 743ms/step - loss: 0.2194 - acc: 0.9133 - val_loss: 0.3168 - val_acc: 0.8600\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 186s 744ms/step - loss: 0.2236 - acc: 0.9071 - val_loss: 0.2906 - val_acc: 0.8830\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 185s 740ms/step - loss: 0.2230 - acc: 0.9065 - val_loss: 0.2899 - val_acc: 0.8735\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 187s 747ms/step - loss: 0.2104 - acc: 0.9119 - val_loss: 0.2853 - val_acc: 0.8740\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 185s 739ms/step - loss: 0.2197 - acc: 0.9056 - val_loss: 0.3167 - val_acc: 0.8640\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 187s 747ms/step - loss: 0.2097 - acc: 0.9118 - val_loss: 0.2901 - val_acc: 0.8780\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 185s 742ms/step - loss: 0.2136 - acc: 0.9113 - val_loss: 0.2974 - val_acc: 0.8715\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 185s 740ms/step - loss: 0.2023 - acc: 0.9134 - val_loss: 0.2972 - val_acc: 0.8670\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 189s 757ms/step - loss: 0.2135 - acc: 0.9133 - val_loss: 0.2818 - val_acc: 0.8800\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 185s 741ms/step - loss: 0.1988 - acc: 0.9160 - val_loss: 0.3212 - val_acc: 0.8715\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 184s 738ms/step - loss: 0.2079 - acc: 0.9135 - val_loss: 0.2845 - val_acc: 0.8750\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 186s 743ms/step - loss: 0.2072 - acc: 0.9168 - val_loss: 0.3237 - val_acc: 0.8575\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 185s 742ms/step - loss: 0.1984 - acc: 0.9189 - val_loss: 0.2860 - val_acc: 0.8745\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 187s 748ms/step - loss: 0.1941 - acc: 0.9211 - val_loss: 0.2843 - val_acc: 0.8815\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 186s 743ms/step - loss: 0.1924 - acc: 0.9220 - val_loss: 0.2885 - val_acc: 0.8785\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 184s 737ms/step - loss: 0.1948 - acc: 0.9201 - val_loss: 0.2963 - val_acc: 0.8700\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 186s 744ms/step - loss: 0.1973 - acc: 0.9176 - val_loss: 0.2996 - val_acc: 0.8800\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 187s 746ms/step - loss: 0.1929 - acc: 0.9238 - val_loss: 0.2956 - val_acc: 0.8650\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 189s 754ms/step - loss: 0.1806 - acc: 0.9274 - val_loss: 0.3297 - val_acc: 0.8535\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 186s 745ms/step - loss: 0.1901 - acc: 0.9219 - val_loss: 0.2992 - val_acc: 0.8705\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 185s 742ms/step - loss: 0.1764 - acc: 0.9259 - val_loss: 0.2784 - val_acc: 0.8815\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 185s 740ms/step - loss: 0.1875 - acc: 0.9211 - val_loss: 0.2744 - val_acc: 0.8800\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 186s 745ms/step - loss: 0.1834 - acc: 0.9260 - val_loss: 0.2925 - val_acc: 0.8780\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 185s 739ms/step - loss: 0.1813 - acc: 0.9275 - val_loss: 0.2856 - val_acc: 0.8770\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 187s 746ms/step - loss: 0.1826 - acc: 0.9243 - val_loss: 0.2908 - val_acc: 0.8855\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 185s 740ms/step - loss: 0.1721 - acc: 0.9284 - val_loss: 0.2985 - val_acc: 0.8710\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 186s 743ms/step - loss: 0.1772 - acc: 0.9305 - val_loss: 0.3269 - val_acc: 0.8510\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 189s 758ms/step - loss: 0.1761 - acc: 0.9281 - val_loss: 0.3324 - val_acc: 0.8540\n"
     ]
    }
   ],
   "source": [
    "classifier = run_training(bs=32, epochs=100)#100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-b821cb2c07b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtraining_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_indices\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'dog'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'training_set' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size = (150, 150))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't pickle _thread.lock objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-0cddd76c9a08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# save the model to disk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'cnn.sav'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: can't pickle _thread.lock objects"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# save the model to disk\n",
    "filename = 'cnn.sav'\n",
    "pickle.dump(classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# load json and create model\\njson_file = open(\\'model.json\\', \\'r\\')\\nloaded_model_json = json_file.read()\\njson_file.close()\\nloaded_model = model_from_json(loaded_model_json)\\n# load weights into new model\\nloaded_model.load_weights(\"model.h5\")\\nprint(\"Loaded model from disk\")'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = classifier.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "classifier.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " \n",
    "# later...\n",
    "\"\"\"\n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
